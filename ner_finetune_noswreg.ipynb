{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc7abbb-6ee6-4d65-a71b-295405fdcd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "import transformers\n",
    "import numpy as np\n",
    "from seqeval.metrics import f1_score\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753764fb-48b8-4675-ae98-068038ec540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_datasets import BPEDropoutTrainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e434ea83-a3c4-4f1c-a4b6-df67e9731621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is enabled.\n",
      "device count: 2, current device: 0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is enabled.\")\n",
    "    print(\"device count: {}, current device: {}\".format(torch.cuda.device_count(), torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"GPU is not enabled.\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d13716f-ed9d-4683-a9d3-aa1c2000525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"./cache\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fef682-c0e2-40b8-8289-f309d83784cb",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8611302b-434f-4f09-97e5-ca95be455681",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"masakhaner\"\n",
    "language = \"amh\"\n",
    "\n",
    "model_path = \"Davlan/afro-xlmr-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d182a459-5486-403b-bb35-f024345aa02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset masakhaner (/atlas2/u/xiluo/temp/cache/masakhaner/amh/1.0.0/e61b24903076a3af7682855beebb820ec64edad0d6787b148c473694592d10b3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981755a80b474effb61a20692ed24eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(dataset_path, language, cache_dir=cache_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceb872b0-2886-478d-b634-32ff694544a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-DATE', 'I-DATE'], id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = dataset['train'].features[\"ner_tags\"].feature\n",
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "716517be-f1a2-4eb5-9cc5-0f63cf6fc0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path, use_fast=True, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4e4881-c18e-4f4b-89fe-3ea577bf769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad3c2ff7-c6ca-45c6-9ace-ad97cca17b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /atlas2/u/xiluo/temp/cache/masakhaner/amh/1.0.0/e61b24903076a3af7682855beebb820ec64edad0d6787b148c473694592d10b3/cache-d966af7eee5cc661.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /atlas2/u/xiluo/temp/cache/masakhaner/amh/1.0.0/e61b24903076a3af7682855beebb820ec64edad0d6787b148c473694592d10b3/cache-727d76e42bfacd12.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e5da135-19ba-431a-b1c5-da709cf3322a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁</td>\n",
       "      <td>ቀዳሚ</td>\n",
       "      <td>ው</td>\n",
       "      <td>▁የ</td>\n",
       "      <td>ሶማሌ</td>\n",
       "      <td>▁ክልል</td>\n",
       "      <td>▁በአ</td>\n",
       "      <td>ወ</td>\n",
       "      <td>ዳይ</td>\n",
       "      <td>...</td>\n",
       "      <td>▁ስነ</td>\n",
       "      <td>▁ስርዓት</td>\n",
       "      <td>ን</td>\n",
       "      <td>▁የተ</td>\n",
       "      <td>መለከተ</td>\n",
       "      <td>▁ዘገባ</td>\n",
       "      <td>▁ነው</td>\n",
       "      <td>▁</td>\n",
       "      <td>፡፡</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_tags</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  1     2     3   4     5     6    7     8     9   ...   21  \\\n",
       "tokens     <s>  ▁   ቀዳሚ     ው  ▁የ   ሶማሌ  ▁ክልል  ▁በአ     ወ    ዳይ  ...  ▁ስነ   \n",
       "ner_tags  -100  0  -100  -100   5  -100     6    6  -100  -100  ...    0   \n",
       "\n",
       "             22    23   24    25    26   27 28    29    30  \n",
       "tokens    ▁ስርዓት     ን  ▁የተ  መለከተ  ▁ዘገባ  ▁ነው  ▁    ፡፡  </s>  \n",
       "ner_tags      0  -100    0  -100     0    0  0  -100  -100  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    [tokenizer.convert_ids_to_tokens(tokenized_dataset['train'][0]['input_ids']), tokenized_dataset['train'][0]['labels']],\n",
    "    index=[\"tokens\", \"ner_tags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473e4846-1e3b-41b2-88bf-fae266403cea",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03e17dcd-3018-4007-8a60-42441fdba362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "# Make debugging easier\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad60b4ec-d886-45d8-afd8-e0bc22cf3cbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./checkpoints/xlm-roberta-ner-swa-noswreg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     log_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     num_train_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m      5\u001b[0m     per_device_train_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m,\n\u001b[1;32m      6\u001b[0m     per_device_eval_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m,\n\u001b[1;32m      7\u001b[0m     evaluation_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     fp16 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m----> 9\u001b[0m     logging_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataset\u001b[49m),\n\u001b[1;32m     10\u001b[0m     push_to_hub \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir = \"./checkpoints/xlm-roberta-ner-swa-noswreg\",\n",
    "    log_level = \"error\",\n",
    "    num_train_epochs = 50,\n",
    "    per_device_train_batch_size = 12,\n",
    "    per_device_eval_batch_size = 12,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    fp16 = True,\n",
    "    logging_steps = len(train_dataset),\n",
    "    push_to_hub = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c62b008d-1236-427f-8ffd-b2a51666f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_func(eval_arg):\n",
    "    preds = np.argmax(eval_arg.predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    y_true, y_pred = [], []\n",
    "    for b in range(batch_size):\n",
    "        true_label, pred_label = [], []\n",
    "        for s in range(seq_len):\n",
    "            if eval_arg.label_ids[b, s] != -100:  # -100 must be ignored\n",
    "                true_label.append(index2tag[eval_arg.label_ids[b][s]])\n",
    "                pred_label.append(index2tag[preds[b][s]])\n",
    "        y_true.append(true_label)\n",
    "        y_pred.append(pred_label)\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "64d2a233-e4a4-494e-b70b-6e497f6b53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = transformers.DataCollatorForTokenClassification(\n",
    "    tokenizer,\n",
    "    return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c627e8ed-a118-4d02-a70f-ffcbf1757c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlmr_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=tags.num_classes,\n",
    "    id2label=index2tag,\n",
    "    label2id=tag2index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "211a250a-0e6d-4fa2-8578-b309054ae281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (transformers.RobertaForTokenClassification\n",
    "         .from_pretrained(model_path, config=xlmr_config, cache_dir=cache_dir)\n",
    "         .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9ea26827-5c6b-4f18-999a-c2f8f689d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = metrics_func,\n",
    "    train_dataset = tokenized_dataset['train'],\n",
    "    eval_dataset = tokenized_dataset['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8cbd3ec0-bcab-40e7-a20d-fe8a36020e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deep/u/xiluo/anaconda3/envs/swreg/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/deep/u/xiluo/anaconda3/envs/swreg/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4632463455200195, 'eval_f1': 0.0, 'eval_runtime': 0.9429, 'eval_samples_per_second': 530.302, 'eval_steps_per_second': 7.424, 'epoch': 1.0}\n",
      "{'eval_loss': 1.3581286668777466, 'eval_f1': 0.0, 'eval_runtime': 0.9428, 'eval_samples_per_second': 530.309, 'eval_steps_per_second': 7.424, 'epoch': 2.0}\n",
      "{'eval_loss': 1.2802386283874512, 'eval_f1': 0.0, 'eval_runtime': 0.9443, 'eval_samples_per_second': 529.467, 'eval_steps_per_second': 7.413, 'epoch': 3.0}\n",
      "{'eval_loss': 1.2069284915924072, 'eval_f1': 0.0, 'eval_runtime': 1.0123, 'eval_samples_per_second': 493.917, 'eval_steps_per_second': 6.915, 'epoch': 4.0}\n",
      "{'eval_loss': 1.136922836303711, 'eval_f1': 0.0, 'eval_runtime': 1.011, 'eval_samples_per_second': 494.542, 'eval_steps_per_second': 6.924, 'epoch': 5.0}\n",
      "{'eval_loss': 1.0697129964828491, 'eval_f1': 0.0, 'eval_runtime': 1.0171, 'eval_samples_per_second': 491.614, 'eval_steps_per_second': 6.883, 'epoch': 6.0}\n",
      "{'eval_loss': 1.00645112991333, 'eval_f1': 0.0, 'eval_runtime': 1.073, 'eval_samples_per_second': 465.97, 'eval_steps_per_second': 6.524, 'epoch': 7.0}\n",
      "{'eval_loss': 0.9485747218132019, 'eval_f1': 0.0, 'eval_runtime': 1.0136, 'eval_samples_per_second': 493.292, 'eval_steps_per_second': 6.906, 'epoch': 8.0}\n",
      "{'eval_loss': 0.8957603573799133, 'eval_f1': 0.0, 'eval_runtime': 0.9432, 'eval_samples_per_second': 530.086, 'eval_steps_per_second': 7.421, 'epoch': 9.0}\n",
      "{'eval_loss': 0.8493614792823792, 'eval_f1': 0.0, 'eval_runtime': 0.9429, 'eval_samples_per_second': 530.278, 'eval_steps_per_second': 7.424, 'epoch': 10.0}\n",
      "{'eval_loss': 0.8107677698135376, 'eval_f1': 0.0, 'eval_runtime': 0.9426, 'eval_samples_per_second': 530.441, 'eval_steps_per_second': 7.426, 'epoch': 11.0}\n",
      "{'eval_loss': 0.7733379006385803, 'eval_f1': 0.0, 'eval_runtime': 0.9431, 'eval_samples_per_second': 530.165, 'eval_steps_per_second': 7.422, 'epoch': 12.0}\n",
      "{'eval_loss': 0.6903766393661499, 'eval_f1': 0.18264840182648404, 'eval_runtime': 0.9437, 'eval_samples_per_second': 529.844, 'eval_steps_per_second': 7.418, 'epoch': 13.0}\n",
      "{'eval_loss': 0.6175341010093689, 'eval_f1': 0.3093220338983051, 'eval_runtime': 1.0086, 'eval_samples_per_second': 495.758, 'eval_steps_per_second': 6.941, 'epoch': 14.0}\n",
      "{'eval_loss': 0.5653538107872009, 'eval_f1': 0.37066881547139413, 'eval_runtime': 1.0084, 'eval_samples_per_second': 495.831, 'eval_steps_per_second': 6.942, 'epoch': 15.0}\n",
      "{'eval_loss': 0.5221443772315979, 'eval_f1': 0.5447219983883965, 'eval_runtime': 1.0091, 'eval_samples_per_second': 495.484, 'eval_steps_per_second': 6.937, 'epoch': 16.0}\n",
      "{'eval_loss': 0.4833284914493561, 'eval_f1': 0.595097210481826, 'eval_runtime': 0.9438, 'eval_samples_per_second': 529.774, 'eval_steps_per_second': 7.417, 'epoch': 17.0}\n",
      "{'eval_loss': 0.46133971214294434, 'eval_f1': 0.5947281713344316, 'eval_runtime': 0.9434, 'eval_samples_per_second': 529.971, 'eval_steps_per_second': 7.42, 'epoch': 18.0}\n",
      "{'eval_loss': 0.43787431716918945, 'eval_f1': 0.6065162907268171, 'eval_runtime': 0.944, 'eval_samples_per_second': 529.67, 'eval_steps_per_second': 7.415, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deep/u/xiluo/anaconda3/envs/swreg/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42189621925354004, 'eval_f1': 0.608096468561585, 'eval_runtime': 1.0157, 'eval_samples_per_second': 492.262, 'eval_steps_per_second': 6.892, 'epoch': 20.0}\n",
      "{'eval_loss': 0.40212559700012207, 'eval_f1': 0.6194539249146759, 'eval_runtime': 1.0081, 'eval_samples_per_second': 495.963, 'eval_steps_per_second': 6.943, 'epoch': 21.0}\n",
      "{'eval_loss': 0.39058101177215576, 'eval_f1': 0.6153846153846154, 'eval_runtime': 0.9431, 'eval_samples_per_second': 530.142, 'eval_steps_per_second': 7.422, 'epoch': 22.0}\n",
      "{'eval_loss': 0.3792569935321808, 'eval_f1': 0.6286672254819782, 'eval_runtime': 0.9439, 'eval_samples_per_second': 529.735, 'eval_steps_per_second': 7.416, 'epoch': 23.0}\n",
      "{'eval_loss': 0.36768636107444763, 'eval_f1': 0.6614583333333334, 'eval_runtime': 0.944, 'eval_samples_per_second': 529.686, 'eval_steps_per_second': 7.416, 'epoch': 24.0}\n",
      "{'eval_loss': 0.3646329939365387, 'eval_f1': 0.6568712186689714, 'eval_runtime': 1.0198, 'eval_samples_per_second': 490.3, 'eval_steps_per_second': 6.864, 'epoch': 25.0}\n",
      "{'eval_loss': 0.3524514436721802, 'eval_f1': 0.6781411359724613, 'eval_runtime': 0.9437, 'eval_samples_per_second': 529.832, 'eval_steps_per_second': 7.418, 'epoch': 26.0}\n",
      "{'eval_loss': 0.34583696722984314, 'eval_f1': 0.689594356261023, 'eval_runtime': 1.0098, 'eval_samples_per_second': 495.146, 'eval_steps_per_second': 6.932, 'epoch': 27.0}\n",
      "{'eval_loss': 0.3401452600955963, 'eval_f1': 0.6866725507502206, 'eval_runtime': 0.9437, 'eval_samples_per_second': 529.847, 'eval_steps_per_second': 7.418, 'epoch': 28.0}\n",
      "{'eval_loss': 0.340925008058548, 'eval_f1': 0.6764199655765922, 'eval_runtime': 0.9776, 'eval_samples_per_second': 511.456, 'eval_steps_per_second': 7.16, 'epoch': 29.0}\n",
      "{'eval_loss': 0.33468225598335266, 'eval_f1': 0.6919758412424504, 'eval_runtime': 1.0016, 'eval_samples_per_second': 499.182, 'eval_steps_per_second': 6.989, 'epoch': 30.0}\n",
      "{'eval_loss': 0.3218282461166382, 'eval_f1': 0.6947368421052632, 'eval_runtime': 1.0119, 'eval_samples_per_second': 494.13, 'eval_steps_per_second': 6.918, 'epoch': 31.0}\n",
      "{'eval_loss': 0.31560760736465454, 'eval_f1': 0.7033747779751333, 'eval_runtime': 0.9437, 'eval_samples_per_second': 529.846, 'eval_steps_per_second': 7.418, 'epoch': 32.0}\n",
      "{'eval_loss': 0.31668350100517273, 'eval_f1': 0.701067615658363, 'eval_runtime': 0.9441, 'eval_samples_per_second': 529.613, 'eval_steps_per_second': 7.415, 'epoch': 33.0}\n",
      "{'eval_loss': 0.31440532207489014, 'eval_f1': 0.7033158813263525, 'eval_runtime': 0.9439, 'eval_samples_per_second': 529.712, 'eval_steps_per_second': 7.416, 'epoch': 34.0}\n",
      "{'eval_loss': 0.31301429867744446, 'eval_f1': 0.7074235807860263, 'eval_runtime': 0.945, 'eval_samples_per_second': 529.097, 'eval_steps_per_second': 7.407, 'epoch': 35.0}\n",
      "{'eval_loss': 0.3073328137397766, 'eval_f1': 0.7077464788732395, 'eval_runtime': 1.0071, 'eval_samples_per_second': 496.484, 'eval_steps_per_second': 6.951, 'epoch': 36.0}\n",
      "{'eval_loss': 0.30423590540885925, 'eval_f1': 0.7145359019264449, 'eval_runtime': 1.0061, 'eval_samples_per_second': 496.947, 'eval_steps_per_second': 6.957, 'epoch': 37.0}\n",
      "{'eval_loss': 0.302978515625, 'eval_f1': 0.7043478260869565, 'eval_runtime': 1.0089, 'eval_samples_per_second': 495.614, 'eval_steps_per_second': 6.939, 'epoch': 38.0}\n",
      "{'eval_loss': 0.2993316054344177, 'eval_f1': 0.702608695652174, 'eval_runtime': 0.944, 'eval_samples_per_second': 529.659, 'eval_steps_per_second': 7.415, 'epoch': 39.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/deep/u/xiluo/anaconda3/envs/swreg/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2995493710041046, 'eval_f1': 0.7101827676240209, 'eval_runtime': 0.9531, 'eval_samples_per_second': 524.583, 'eval_steps_per_second': 7.344, 'epoch': 40.0}\n",
      "{'eval_loss': 0.30170440673828125, 'eval_f1': 0.7008547008547009, 'eval_runtime': 0.9758, 'eval_samples_per_second': 512.382, 'eval_steps_per_second': 7.173, 'epoch': 41.0}\n",
      "{'eval_loss': 0.29742953181266785, 'eval_f1': 0.7062876830318691, 'eval_runtime': 1.0062, 'eval_samples_per_second': 496.935, 'eval_steps_per_second': 6.957, 'epoch': 42.0}\n",
      "{'eval_loss': 0.29559406638145447, 'eval_f1': 0.7120689655172414, 'eval_runtime': 1.0114, 'eval_samples_per_second': 494.342, 'eval_steps_per_second': 6.921, 'epoch': 43.0}\n",
      "{'eval_loss': 0.2955131530761719, 'eval_f1': 0.7005163511187608, 'eval_runtime': 1.0084, 'eval_samples_per_second': 495.812, 'eval_steps_per_second': 6.941, 'epoch': 44.0}\n",
      "{'eval_loss': 0.29284873604774475, 'eval_f1': 0.7063903281519861, 'eval_runtime': 0.9429, 'eval_samples_per_second': 530.255, 'eval_steps_per_second': 7.424, 'epoch': 45.0}\n",
      "{'eval_loss': 0.29236170649528503, 'eval_f1': 0.7106863596872285, 'eval_runtime': 0.9459, 'eval_samples_per_second': 528.577, 'eval_steps_per_second': 7.4, 'epoch': 46.0}\n",
      "{'eval_loss': 0.2921116054058075, 'eval_f1': 0.7050610820244327, 'eval_runtime': 0.9445, 'eval_samples_per_second': 529.396, 'eval_steps_per_second': 7.412, 'epoch': 47.0}\n",
      "{'eval_loss': 0.29191309213638306, 'eval_f1': 0.7073170731707316, 'eval_runtime': 1.0178, 'eval_samples_per_second': 491.234, 'eval_steps_per_second': 6.877, 'epoch': 48.0}\n",
      "{'eval_loss': 0.29207637906074524, 'eval_f1': 0.7130584192439862, 'eval_runtime': 1.0197, 'eval_samples_per_second': 490.345, 'eval_steps_per_second': 6.865, 'epoch': 49.0}\n",
      "{'eval_loss': 0.29167571663856506, 'eval_f1': 0.7166236003445307, 'eval_runtime': 1.0058, 'eval_samples_per_second': 497.121, 'eval_steps_per_second': 6.96, 'epoch': 50.0}\n",
      "{'train_runtime': 470.5249, 'train_samples_per_second': 185.963, 'train_steps_per_second': 2.657, 'train_loss': 0.528118701171875, 'epoch': 50.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=0.528118701171875, metrics={'train_runtime': 470.5249, 'train_samples_per_second': 185.963, 'train_steps_per_second': 2.657, 'train_loss': 0.528118701171875, 'epoch': 50.0})"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb52bf-6af9-4ad5-a49c-a1b88b8115e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f806e89-860b-4725-a5f8-54fede5a5ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
